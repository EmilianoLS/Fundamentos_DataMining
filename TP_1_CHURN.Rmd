---
title: "R Notebook"
output: html_notebook
---

Importo las librerias que voy a usar



```{r}
library("stringr")
library("data.table")
library(ggplot2)
library(dplyr)
library(gridExtra)
library(reshape2)
library(stats)
library(corrplot)
library(class)
library(fastDummies)
library(rpart)
library(caret)
library(rpart.plot)
library(randomForest)
library(caTools)
```

Defino funcion para cargar todos los data frames de entrenamiento

```{r}
load_csv_data <- function(csv_file, sample_ratio = 1, drop_cols = NULL,
                          sel_cols = NULL) {
  # Esta funcion carga un unico csv con los parametros que le indique
  
  dt <- fread(csv_file, header = TRUE, sep = ",", stringsAsFactors = TRUE,
              na.strings = "", drop = drop_cols, select = sel_cols,
              showProgress = TRUE)
  return(dt)
}



load_train_data <- function(data_dir, train_file="/train_", sample_ratio=1,
                            drop_cols=NULL, sel_cols=NULL) {
  # Esta funcion se encarga de concatenar todos los dataframes juntos
  
  
  
  train_days <- seq(1, 5, by=1)
  
  dfs <- list()
  
  for (i in train_days){
  
    dfs[[i]] <- load_csv_data(csv_file = paste(data_dir,train_file,as.character(i),".csv", sep = ''), 
                              sample_ratio = sample_ratio, drop_cols = drop_cols, sel_cols = sel_cols)
  }
  
  # Uno todos los dataframes en uno solo
  
  df <- (rbindlist(dfs, fill=TRUE))
  
  # Reordeno las columnas alfabeticamente
  
  setcolorder(df, sort(colnames(df)))
  
  # Creo la columna Label con las condiciones de churn explicadas
  
  df[, Label := as.numeric(Label_max_played_dsi == 3)] 
  set.seed(123)
  if (sample_ratio < 1) {
    
    sample_size <- as.integer(sample_ratio * nrow(df))
    
    df <- df[sample(.N, sample_size)]
  }
  
  rm(dfs)
  
  
  return(df)
}
```

Cargo dataframe de un tamaño del 10% del original

```{r}
csv_dir <- "C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Mineria de datos/datasets"

train <- load_train_data(csv_dir, sample_ratio = 1)
train$churn <- train$Label == 1
```

```{r}
head((train));dim(train)
```

```{r}
summary(train)
```

* La columna 'age' no puede tomarse para analizar por su alto contenido de NAs, no podemos inferir estos datos de ninguna forma
* La columna 'BuyCard_sum_dsi1' tiene valores negativos, esto pareciera ser un error, y viendo el comportamiento en las demas columnas de este estilo, podria imputarse el valor 0 a estos negativos

Reviso las columnas con valores nulos y sus porcentajes
Para eso creo una función que me trae el porcentaje de nulos en las columnas que unicamente tienen nulos

```{r}
find_nulls <- function(df){
    columnas_nas <- list()

    for (i in colnames(df)){
      nans <- nrow(filter(select(df,i), !complete.cases(select(df,i))))

      if (nans != 0){

        columnas_nas[[i]] <- (nans/nrow(df))*100
      }

    }
    return(columnas_nas)
    }

as.data.frame(find_nulls(train))
```


Hago una analítica sobre algunas variables para entender su relación con la target a predecir

```{r}
ggplot(train) + geom_bar(mapping = aes(x = TutorialFinish, fill = churn), position = 'fill') +
labs(x = 'Termino el tutorial', y = '% churn') +
ggtitle('Proporcion de churn según terminó o no el tutorial')
```

Me imagino que una persona haría Churn según haya perdido más batallas en los primeros días. Pongo a prueba esa suposición creando la sumatoria de las variables Lose battle, Win battle y Start battle

```{r}
train$sum_lost_battles <- train$LoseBattle_sum_dsi0 + train$LoseBattle_sum_dsi1 + train$LoseBattle_sum_dsi2 + train$LoseBattle_sum_dsi3
train$sum_win_battles <- train$WinBattle_sum_dsi0 + train$WinBattle_sum_dsi1 + train$WinBattle_sum_dsi2 + train$WinBattle_sum_dsi3
train$sum_start_battle <- train$StartBattle_sum_dsi0 + train$StartBattle_sum_dsi1 + train$StartBattle_sum_dsi2 + train$StartBattle_sum_dsi3

# Tomo una muestra del 10% del total para graficar los puntos porque sino es muy pesado

set.seed(123)
sample_size <- as.integer(0.1 * nrow(train))    
df <- train[sample(.N, sample_size)]

ggplot(filter(df, complete.cases(sum_start_battle))) +
geom_point(mapping = aes(x = sum_start_battle, y = sum_lost_battles, color = churn), alpha = 0.3) +
geom_smooth(mapping = aes(x = sum_start_battle, y = sum_lost_battles)) +
labs(x = 'Batallas iniciadas', y = 'Batallas perdidas') +
ggtitle('Batallas perdidas vs Batallas iniciadas')
```

Podría ocurrir que haya alguna relación entre la cantidad de sesiones iniciadas y el hecho de hacer churn. Se busca la cantidad de sesiones iniciadas para los primeros 4 días desde la instalación hasta el día 3, para ambos grupos.

Luego se calcula la media de sesiones iniciadas para entender si verdaderamente hay una relación

```{r}
train_melt <- melt(select(train, user_id, StartSession_sum_dsi0,StartSession_sum_dsi1,StartSession_sum_dsi2,
                          StartSession_sum_dsi3, churn), id = c('user_id','churn'))

grafico <- train_melt %>% group_by(variable,churn) %>% summarize(total = sum(value)) %>% ungroup()
grafico

ggplot(grafico, mapping = aes(x = total, y = variable, fill = churn)) +
geom_bar(color = 'black',stat = 'identity', position = 'dodge') + facet_wrap(~churn, ncol = 1) +
labs(x = 'Total de sesiones', y = 'Dia') +
ggtitle('Cantidad de sesiones por día')
```

Agrupo por dia desde la instalacion y calculo el intervalo de confianza para la media

```{r}
grafico_2 <- train_melt %>% group_by(variable,churn) %>%
summarize(intervalo_inf = t.test(value, conf.level = 0.95)$conf.int[1], 
         intervalo_sup = t.test(value, conf.level = 0.95)$conf.int[2],
         mean = mean(value)) %>% ungroup()

grafico_2

ggplot(grafico_2) +
geom_point(mapping = aes(x = mean, y = variable, fill = churn),color = 'black',stat = 'identity') + 
geom_errorbar(aes(xmin = intervalo_inf, xmax = intervalo_sup, y = variable), color = 'red') +
facet_wrap(~churn, ncol = 1) +
labs(x = 'Media de sesiones', y = 'Dia') + 
ggtitle('Cantidad de sesiones promedio por día')
```

Quiero entender la cantidad de instalaciones por día que hay, para ver si hay alguna tendencia

```{r}
grafico_3 <- train %>% group_by(install_date) %>% summarize(total_installed = n()) %>% ungroup()

ggplot(grafico_3) + geom_line(mapping = aes(x = install_date, y = total_installed)) +
geom_vline(xintercept = c(398:399), color = 'red', linetype = 'dashed') +
geom_vline(xintercept = c(134,29,133,28,246), color = 'blue', linetype = 'dashed') +
geom_text(aes(x = 134, label="\n 34260 instalaciones", y = 30000), colour="blue", angle=90, text=element_text(size=5)) + 
geom_text(aes(x = 29, label="\n 32773 instalaciones", y = 30000), colour="blue", angle=90, text=element_text(size=5))+
geom_text(aes(x = 243, label="\n 29196 instalaciones", y = 30000), colour="blue", angle=90, text=element_text(size=5)) +
labs(x = 'Dia de instalacion', y = 'Cantidad de instalaciones') + 
ggtitle('Evolucion de las instalaciones')
```

Busco si existe una relación entre la cantidad de batallas ganadas/ batallas perdidas

```{r}
train$rt_lose_win_0 <- train$WinBattle_sum_dsi0 - train$LoseBattle_sum_dsi0
train$rt_lose_win_1 <- train$WinBattle_sum_dsi1 - train$LoseBattle_sum_dsi1
train$rt_lose_win_2 <- train$WinBattle_sum_dsi2 - train$LoseBattle_sum_dsi2
train$rt_lose_win_3 <- train$WinBattle_sum_dsi3 - train$LoseBattle_sum_dsi3

train_melt <- melt(select(train, user_id, rt_lose_win_0,rt_lose_win_1,rt_lose_win_2,
                          rt_lose_win_3, churn), id = c('user_id','churn'))

grafico_4 <- train_melt %>% group_by(variable,churn) %>%
summarize(intervalo_inf = t.test(value, conf.level = 0.95)$conf.int[1], 
         intervalo_sup = t.test(value, conf.level = 0.95)$conf.int[2],
         mean = mean(value)) %>% ungroup()

ggplot(grafico_4) +
geom_point(mapping = aes(x = mean, y = variable, fill = churn),color = 'black',stat = 'identity') + 
geom_errorbar(aes(xmin = intervalo_inf, xmax = intervalo_sup, y = variable), color = 'red') +
facet_wrap(~churn, ncol = 1) +
labs(x = 'Media de resultados por dia', y = 'Dia') + 
ggtitle('Resultados promedio por día')
```

Promedio de batallas perdidas por día

```{r}
train_melt <- melt(select(train, user_id, LoseBattle_sum_dsi0,LoseBattle_sum_dsi1,LoseBattle_sum_dsi2,
                          LoseBattle_sum_dsi3, churn), id = c('user_id','churn'))

grafico_5 <- train_melt %>% group_by(variable,churn) %>%
summarize(intervalo_inf = t.test(value, conf.level = 0.95)$conf.int[1], 
         intervalo_sup = t.test(value, conf.level = 0.95)$conf.int[2],
         mean = mean(value)) %>% ungroup()

ggplot(grafico_5) +
geom_point(mapping = aes(x = mean, y = variable, fill = churn),color = 'black',stat = 'identity') + 
geom_errorbar(aes(xmin = intervalo_inf, xmax = intervalo_sup, y = variable), color = 'red') +
facet_wrap(~churn, ncol = 1) +
labs(x = 'Media de batallas perdidas', y = 'Dia') + 
ggtitle('Batallas perdidas en promedio por día')
```

Promedio de batallas iniciadas (esto lo hago para entender si la menor cantidad de batallas perdidas por aquellos que hicieron churn en el gráfico anterior se debe a que jugaron menos)

```{r}
train_melt <- melt(select(filter(train,complete.cases(StartBattle_sum_dsi1)), user_id,
                          StartBattle_sum_dsi0,StartBattle_sum_dsi1,StartBattle_sum_dsi2,
                          StartBattle_sum_dsi3, churn), id = c('user_id','churn'))

grafico_6 <- train_melt %>% group_by(variable,churn) %>%
summarize(intervalo_inf = t.test(value, conf.level = 0.95)$conf.int[1], 
         intervalo_sup = t.test(value, conf.level = 0.95)$conf.int[2],
         mean = mean(value)) %>% ungroup()

ggplot(grafico_6) +
geom_point(mapping = aes(x = mean, y = variable, fill = churn),color = 'black',stat = 'identity') + 
geom_errorbar(aes(xmin = intervalo_inf, xmax = intervalo_sup, y = variable), color = 'red') +
facet_wrap(~churn, ncol = 1) +
labs(x = 'Media de batallas inicidadas', y = 'Dia') + 
ggtitle('Batallas iniciadas en promedio por día')
```

Feature Engineering
-------------------

Ahora que ya preparamos una analitica y comprendemos un poco mejor los datos, procedemos a preparar las variables para poder aplicarles un modelo.

Primero tengo que excluir los casos no confiables: Todos aquellos que tengan Label_max_played_dsi igual a 3, que hayan sido instalados en los dias que van de 383 a 395 inclusive, ya que no son validos (desconozco si la persona hizo churn o no).

Entreno con un solo set de entrenamiento para manejar mejor los datos.

```{r}
setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Mineria de datos/datasets')

train_data <- load_csv_data('train_4.csv', sample_ratio = 0.8)
train_data[, Label := factor(ifelse(Label_max_played_dsi == 3,
                                  "churn", "no_churn"))]

train_filtered <- filter(train_data, !(Label_max_played_dsi == 3 & install_date %in% (c(383:395))))
train_filtered$random <- rnorm(nrow(train_filtered), mean = 15)
```

Antes de avanzar sobre la separación del dataset en conjuntos de train, validation & test se evaluan que variables podran llegar a ser relevantes o no para el modelo.


Como se habia visto anteriormente, las variables de age y site tienen un alto porcentaje de valores faltantes, y no es posible imputarlos de ninguna forma, por lo que se desconsideran para el modelo. Esto es lamentable en el caso de age, ya que probablemente (no lo sabemos), podria haber sido un predictor importante.

Por otro lado, el resto de las columnas con valores nulos se decide imputarles la media. Excepto por device_model, que se decidio eliminar los registros nulos porque son muy pocos y no afectará al modelo significativamente. Tambien se elimniaran los registros nulos de country porque, si bien podria llegar a ser una columna importante, solamente estariamos borrando el 2% de los registros

Tambien se vio que la columna BuyCard_sum_dsi_1 tiene valores negativos! Si bien esto se puede interpretar como que se le 'regalo' una carta, el hecho de que en las otras columnas de BuyCard_sum_dsi no hubiese valores negativos, lleva a pensar que son valores erroneos. Tomamos la decision de convertir estos valores negativos a 0, ya que es lo mas comun que observamos en las otras (entendemos el error que esto puede traer, pero es mejor que descartar completamente esta columna)

```{r}
# Reemplazo valores negativos de la columna BuyCard_sum_dsi1 con cero

train_filtered$BuyCard_sum_dsi1[train_filtered$BuyCard_sum_dsi1 < 0] <- 0
# Ecluyo las columnas age y site de mi dataframe

train_filtered <- select(train_filtered, -c(age, site))

# Elimnio los registros NA en la columna device_model

train_filtered <- filter(train_filtered, complete.cases(device_model))

# Imputo la media para el resto de las columnas con nulos

na_cols <- colnames(as.data.frame(find_nulls(select_if(train_filtered, is.numeric))))
for (i in na_cols){

    train_filtered[is.na(train_filtered[,i]),i] <- round(mean(train_filtered[,i], na.rm = TRUE))  
}

# Elimnio los registros NA en la columna country

train_filtered <- filter(train_filtered, complete.cases(country))
```

```{r}
colSums(is.na(train_filtered))[colSums(is.na(train_filtered)) > 0]
```
Se toma la decision de desconsiderar la columna categorical_7 porque entre las 7 columnas categorical, se juntan muchas variables categoricas como para poder manejarlas en el modelo, terminarian quedando muchas columnas. Por eso en esta primera etapa no se tomarán en cuenta.

```{r}
train_filtered <- select(train_filtered, -c(categorical_1,categorical_2,categorical_3,categorical_4,
                                           categorical_5,categorical_6,categorical_7,user_id, id,Label_max_played_dsi))
```                                  

Verifico que todas las variables tengan el type correcto

```{r}
sapply(train_filtered, class)
```


Se ve que la variable target es numerica y deberia ser un factor, y existen valores numericos en algunas variables como OpenChest_sum_dsi2, que deberian ser int (sino trae valores con coma, esto no tiene sentido)

```{r}
train_filtered <- transform(train_filtered,
                            OpenChest_sum_dsi2 = as.integer(OpenChest_sum_dsi2),
                            TutorialStart = as.factor(TutorialStart),
                            TutorialStartPart1 = as.factor(TutorialStartPart1),
                            TutorialStartPart2 = as.factor(TutorialStartPart2),
                            TutorialStartPart3 = as.factor(TutorialStartPart3),
                            TutorialStartPart4 = as.factor(TutorialStartPart4),
                            TutorialStartPart5 = as.factor(TutorialStartPart5),
                            TutorialStartPart6 = as.factor(TutorialStartPart6),
                            TutorialFinish = as.factor(TutorialFinish),
                            StartBattle_sum_dsi1 = as.integer(StartBattle_sum_dsi1),
                            ChangeArena_sum_dsi3 = as.integer(ChangeArena_sum_dsi3),
                            BuyCard_sum_dsi1 = as.integer(BuyCard_sum_dsi1)

                            )
```


# Separo en conjunto de train y validacion

Voy a separar en dos conjuntos para entrenar y validar posteriormente, siempre trabajando con el dataset de train_4, despues, voy a usar el conjunto de train_5 para validar con datos 100% nuevos

```{r}

set.seed(123)
val_index <- sample(c(1:nrow(train_filtered)), nrow(train_filtered)*0.2)

train_data_tr <- train_filtered[-val_index,]
val_data <- train_filtered[val_index,]

```


Ahora aplico distintos modelos y preprocesamientos, validando contra el conjunto de validacion para ver si cualquier modificacion que haga esta mejorando o empeorando el modelo

# Dataset crudo con un random forest 

### Busco eliminar variables innecesarias (todavia genero nuevas ni elimine outliers)


```{r}

rf <- randomForest(ntree = 100,
                   importance = TRUE,
                   Label ~ .,
                   data = select(val_data, -c(country,device_model))
  
)
```

```{r}
rf
```


```{r}

# Creo un dataframe con la importancia de cada variable

important_feautres <- as.data.frame(importance(rf))

important_feautres$features <- as.factor(rownames(important_feautres))

# Cambio el nombre de una columna

#names(important_feautres)[3] <- 'relevance'

# Grafico

options(repr.plot.width = 14, repr.plot.height = 25)
ggplot(important_feautres, aes(y = reorder(features, MeanDecreaseAccuracy), x = MeanDecreaseAccuracy)) + geom_bar(stat = "identity")

#plot(importance(rf))
```

Me quedo con las variables que tienen una importancia superior a la random

```{r}

#not_important_features <- c(select(filter(important_feautres, MeanDecreaseAccuracy < important_feautres$MeanDecreaseAccuracy[important_feautres$features == 'random']),features))

not_important_features <- c('LoseTournamentBattle_sum_dsi2','LoseTournamentBattle_sum_dsi1','LoseTournamentBattle_sum_dsi0','StartTournamentBattle_sum_dsi1','LoseTournamentBattle_sum_dsi3','StartTournamentBattle_sum_dsi0','WinTournamentBattle_sum_dsi3','QuitTournament_sum_dsi3','WinTournamentBattle_sum_dsi2','QuitTournament_sum_dsi0','JoinTournament_sum_dsi1','StartTournamentBattle_sum_dsi3','WinTournamentBattle_sum_dsi0','OpenPiggyBank_sum_dsi3','traffic_type','JoinTournament_sum_dsi2','JoinTournament_sum_dsi0','OpenPiggyBank_sum_dsi2','QuitTournament_sum_dsi1','QuitTournament_sum_dsi2','WinTournamentBattle_sum_dsi1','StartTournamentBattle_sum_dsi2','country','device_model','random','JoinTournament_sum_dsi3','TutorialStart','install_date','TutorialStartPart1','OpenPiggyBank_sum_dsi1','TutorialStartPart3','StartGameplayModeBattle_sum_dsi0','TutorialStartPart5','TutorialFinish','ChangeArena_sum_dsi3','OpenPiggyBank_sum_dsi0','TutorialStartPart6','StartGameplayModeBattle_sum_dsi1','BuyCard_sum_dsi3','StartGameplayModeBattle_sum_dsi3','TutorialStartPart4','TutorialStartPart2','platform','StartGameplayModeBattle_sum_dsi2','BuyCard_sum_dsi2') #volver a meter la random
```




# Modelo 1

Pruebo de nuevo el random forest solo con lo mas relevante (tarda mucho)


```{r}
rf <- randomForest(ntree = 100,
                   Label ~ .,
                   data = select(train_data_tr, -not_important_features))
```

```{r}

rf

```

# Modelo 2

Probando un modelo super sencillo de un solo arbol (pruebo sobre todo el data train, ya no sobre el conjunto de validacion porque ya elimine las variables menos descriptivas)


```{r}

fitControl <- trainControl(method = "cv",
                           number = 5,
                           verboseIter = TRUE,
                           classProbs=TRUE,
                           summaryFunction = twoClassSummary)


rpart_fit_grid <- train(x = train_data_tr %>% select(c(-not_important_features, - Label)),
                        y = train_data_tr$Label,
                        method = "rpart",
                        trControl = fitControl,
                        na.action = "na.omit",
                        metric = "ROC")

```

```{r}
rpart_fit_grid$results[which.max(rpart_fit_grid$results$ROC),]
```

Pruebo sobre el conjunto de validacion


```{r}

# Predecimos sobre los datos de evaluación
eval_preds <- data.frame(Label = predict(rpart_fit_grid,
                                         select(val_data,-c(not_important_features,Label))))

```

Muestro matriz de confusion

```{r}
eval_preds$Real <- val_data$Label

table(predicho = eval_preds$Label, real = eval_preds$Real)

```



Separo en conjunto de train, validation & test

El criterio que se tomo, en función de lo que se observa en el gráfico de churn en función del install date, es tomar los ultimos de instalaciones para los conjuntos de validacion y testeo. El motivo de esto es que son mis variables "futuras" dentro de los datos que tengo, por lo cual, es lógico que se intente recrear un escenario similar al que se tendra cuando se quiera predecir datos nuevos.

Se toma:

El último 2,5% de los datos para testeo
El restante 2,5% de los ultimos datos para evaluacion
Lo que resta de los datos para entrenamiento, los cuales a su vez se van a resamplear mediante k-fold

```{r}
grafico_7 <- train_filtered %>% group_by(install_date) %>% summarize(sum_churn = sum(churn)) %>% ungroup()
ggplot(grafico_7) + geom_line(mapping = aes(x = install_date, y = sum_churn))
```

Ordeno el dataframe segun la fecha de instalación para poder separar los ultimos registros para mi conjunto de testeo y validacion

```{r}
train_filtered <- train_filtered[order(train_filtered$install_date),]
rownames(train_filtered) <- c(1:nrow(train_filtered))
```

Descarto columnas generadas anteriormente para armar gráficos, así como tambien la fecha de instalacion, el id y el user_id, el device_model, el traffic_type y el country. 

Todas menos traffic_type se descartaron porque al ser categóricas, convertirlas a un valor numérico que el modelo pueda aprovechar implicaría agregar muchisimas columnas, lo que no es óptimo.
En el caso de traffic_type, esta tenía 0 variabilidad, todos los registros tenían el mismo número por lo que se descarta.

```{r}
train_filtered <- select(train_filtered, -c(install_date,id,user_id,device_model, traffic_type,
                                            churn, sum_lost_battles, sum_start_battle, rt_lose_win_0,
                                           rt_lose_win_1,rt_lose_win_2,rt_lose_win_3, sum_win_battles,
                                            country))
```


```{r}
train_filtered<- select(dummy_cols(train_filtered), -c(platform))

```
Convierto la columna Label en un factor para usar en el modelo


```{r}
train_filtered$Label <- as.factor(train_filtered$Label)
```

Ahora si, con las variables "listas", separo los grupos de validation, testing y training
```{r}
# Conjunto de testeo

test_data <- train_filtered[c((nrow(train_filtered)-round(nrow(train_filtered)*0.025)):nrow(train_filtered)),]

# Conjunto de validacion

validation_data <-train_filtered[c((nrow(train_filtered)-(round(nrow(train_filtered)*0.025))*2)):c((nrow(train_filtered)-round(nrow(train_filtered)*0.025))-1),]

# Conjunto de entrenamiento

train_data <- train_filtered[c(0:(nrow(train_filtered) - nrow(test_data) - nrow(validation_data))),]

# Saco la columna Label max played dsi porque es anaolga al target, por lo que en el futuro va a perjudicar al modelo

test_data <- select(test_data, -c(Label_max_played_dsi))
validation_data <- select(validation_data, -c(Label_max_played_dsi))
train_data <- select(train_data, -c(Label_max_played_dsi))
```


# Hago prediccion sobre el conjunto de evaluacion



```{r}
csv_dir <- "C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Mineria de datos/datasets/evaluation.csv"

evaluation <- load_csv_data(csv_dir, sample_ratio = 1)


evaluation <- transform(evaluation,
                            OpenChest_sum_dsi2 = as.integer(OpenChest_sum_dsi2),
                            TutorialStart = as.factor(TutorialStart),
                            TutorialStartPart1 = as.factor(TutorialStartPart1),
                            TutorialStartPart2 = as.factor(TutorialStartPart2),
                            TutorialStartPart3 = as.factor(TutorialStartPart3),
                            TutorialStartPart4 = as.factor(TutorialStartPart4),
                            TutorialStartPart5 = as.factor(TutorialStartPart5),
                            TutorialStartPart6 = as.factor(TutorialStartPart6),
                            TutorialFinish = as.factor(TutorialFinish),
                            StartBattle_sum_dsi1 = as.integer(StartBattle_sum_dsi1),
                            ChangeArena_sum_dsi3 = as.integer(ChangeArena_sum_dsi3),
                            BuyCard_sum_dsi1 = as.integer(BuyCard_sum_dsi1)

                            )
```

Me quedo con las mismas columnas que use en el entrenamiento

```{r}
selected_columns <- colnames(select(train_data_tr, -c(Label, not_important_features)))

evaluation <- select(evaluation,selected_columns)

```


```{r}
# Predecimos sobre los datos de evaluación

eval_preds <- data.frame(id = 0:(nrow(evaluation)-1),
                         Label = predict(rpart_fit_grid,
                                         evaluation, type = "prob")[,"churn"])

# Armo el archivo para subir a Kaggle
write.table(eval_preds, "modelo_3_rpart.csv",
            sep = ",", row.names = FALSE)

```

Quiero fijarme si hay valores nulos para imputar

```{r}

colSums(is.na(evaluation))[colSums(is.na(evaluation)) > 0]
```
```{r}

# Imputo la media para el resto de las columnas con nulos


evaluation$ChangeArena_sum_dsi3[is.na(evaluation$ChangeArena_sum_dsi3)] <- 0
evaluation$OpenChest_sum_dsi2[is.na(evaluation$OpenChest_sum_dsi2)] <- 4
evaluation$StartBattle_sum_dsi1[is.na(evaluation$StartBattle_sum_dsi1)] <- 13

#evaluation[is.na(evaluation[,ChangeArena_sum_dsi3]),ChangeArena_sum_dsi3]  #round(mean(evaluation[,ChangeArena_sum_dsi3], na.rm = TRUE))

#evaluation[is.na(evaluation[,OpenChest_sum_dsi2]),OpenChest_sum_dsi2] <- 4 #round(mean(evaluation[,OpenChest_sum_dsi2], na.rm = TRUE))

#evaluation[is.na(evaluation[,StartBattle_sum_dsi1]),StartBattle_sum_dsi1] <- 13 #round(mean(evaluation[,StartBattle_sum_dsi1], na.rm = TRUE))

```

```{r}

colSums(is.na(evaluation))[colSums(is.na(evaluation)) > 0]
```

Convierto la variable platform en una variable numerica

```{r}
evaluation <- select(dummy_cols(evaluation), -c(platform))
```

Aplico mi mejor modelo al conjunto validacion
```{r}
dim(evaluation); dim(train_data)

```

```{r}
holdout_index  <- sample(c(1:nrow(train_data)), 200000)
train_data_reduced <- train_data[-holdout_index,]
ts_pred <- knn(select(train_data_reduced,-c(Label,Label_max_played_dsi)), evaluation,
              train_data_reduced$Label, 30, prob = TRUE)
```
